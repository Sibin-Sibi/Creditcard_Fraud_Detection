{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from subprocess import check_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "pd.pandas.set_option('display.max_columns',None) \n",
    "import pandas.util.testing as tm\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading dataframe\n",
    "data = pd.read_excel('creditcard.xlsb', engine='pyxlsb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data has zero missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets start looking the difference by Normal and Fraud transactions\n",
    "print(\"Distribuition of Normal(0) and Frauds(1): \")\n",
    "print(data[\"Class\"].value_counts())\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(data[\"Class\"], palette = 'ch:.25')\n",
    "plt.title(\"Class Count\", fontsize=18)\n",
    "plt.xlabel(\"Is fraud?\", fontsize=15)\n",
    "plt.ylabel(\"Count\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Features and some Feature Engineering\n",
    "\n",
    "As our Time feature are in seconds we will transform it ot minutes and hours to get a better understand of the patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta = pd.to_timedelta(data['Time'], unit = 's')\n",
    "data['Time_min'] = (timedelta.dt.components.minutes).astype(int)\n",
    "data['Time_hr'] = (timedelta.dt.components.hours).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,6))\n",
    "\n",
    "sns.distplot( data[data[\"Class\"] == 0]['Time_min'] ,  color = 'g')\n",
    "sns.distplot( data[data[\"Class\"] == 1]['Time_min'], color = 'r')\n",
    "plt.title('Fraud(red) vs normal transaction(green)) by minutes', fontsize = 17)\n",
    "plt.legend()\n",
    "                        \n",
    "plt.xlim(-1,61)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,5))\n",
    "\n",
    "sns.distplot(data[data[\"Class\"]== 0]['Time_hr'], color = 'g')\n",
    "sns.distplot(data[data['Class']==1]['Time_hr'], color= 'r')\n",
    "plt.title(\"Fraud(red) vs normal transaction(green)) by hour\")\n",
    "\n",
    "plt.xlim(-1,25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the fraud transation is not much dependent on the time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = data.corr()\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "sns.heatmap(correlation_matrix,vmax=0.8,square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correlation matrix shows that none of the V1 to V28 PCA components have any correlation to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fraud = data[data['Class']==1]\n",
    "Valid = data[data['Class']==0]\n",
    "outlier_fraction = len(Fraud)/float(len(Valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"Class\"], axis = 1)\n",
    "Y = data[\"Class\"]\n",
    "\n",
    "# Define a random state \n",
    "state = np.random.RandomState(42)\n",
    "X_outliers = state.uniform(low=0, high=1, size=(X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The types of algorithms we are going to use to try to do anomaly detection on this dataset are as follows\n",
    "\n",
    "1. Isolation Forest Algorithm:\n",
    "2. Local Oulier Factor Algorithm\n",
    "3. Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Isolation Forest\":IsolationForest(n_estimators=100, max_samples=len(X), \n",
    "                                       contamination=outlier_fraction,random_state=state, verbose=0),\n",
    "    \"Local Outlier Factor\":LocalOutlierFactor(n_neighbors=20, algorithm='auto', \n",
    "                                              leaf_size=30, metric='minkowski',\n",
    "                                              p=2, metric_params=None, contamination=outlier_fraction),\n",
    "    \"Support Vector Machine\":OneClassSVM(kernel='rbf', degree=3, gamma=0.1,nu=0.05, \n",
    "                                         max_iter=-1, random_state=state)\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_outliers = len(Fraud)\n",
    "for i, (clf_name,clf) in enumerate(classifiers.items()):\n",
    "    #Fit the data and tag outliers\n",
    "    if clf_name == \"Local Outlier Factor\":\n",
    "        y_pred = clf.fit_predict(X)\n",
    "        scores_prediction = clf.negative_outlier_factor_\n",
    "    else:    \n",
    "        clf.fit(X)\n",
    "        scores_prediction = clf.decision_function(X)\n",
    "        y_pred = clf.predict(X)\n",
    "    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n",
    "    y_pred[y_pred == 1] = 0\n",
    "    y_pred[y_pred == -1] = 1\n",
    "    n_errors = (y_pred != Y).sum()\n",
    "    # Run Classification Metrics\n",
    "    print(\"{}: {}\".format(clf_name,n_errors))\n",
    "    print(\"Accuracy Score :\")\n",
    "    print(accuracy_score(Y,y_pred))\n",
    "    print(\"Classification Report :\")\n",
    "    print(classification_report(Y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
